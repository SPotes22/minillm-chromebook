"""
poeta_from_scratch.py - Crear poeta funcional desde cero
"""

import numpy as np
import pickle
import json

print("üé≠ CREANDO POETA FUNCIONAL DESDE CERO")
print("=" * 50)

# 1. VOCABULARIO SENSATO
vocab = {}
id_to_token = {}

# Palabras de TUS poemas
poem_words = [
    # De tus poemas
    'amor', 'vida', 'muerte', 'alma', 'coraz√≥n', 'poes√≠a', 'verso',
    'noche', 'd√≠a', 'tiempo', 'universo', 'luz', 'sombra', 'mar',
    'cielo', 'tierra', 'fuego', 'agua', 'aire', 'sangre', 'l√°grima',
    'risa', 'dolor', 'alegr√≠a', 'tristeza', 'esperanza', 'memoria',
    'sue√±o', 'realidad', 'fantas√≠a', 'verdad', 'mentira', 'camino',
    'destino', 'azar', 'libertad', 'prisi√≥n', 'guerra', 'paz',
    
    # Tu vocabulario personal
    'cabellos', 'casta√±os', 'cuerpo', 'alegria', 'macarena', 'infierno',
    'quijote', 'koi', 'ed√©n', 'jazz', 'mozart', 'orquesta', 'desierto',
    'oasis', 'tormenta', 'luci√©rnaga', 'petalos', 'rosa', 'ceniza',
    'hoguera', 'herej√≠a', 'frecuencia', 'lienzo', 'melancol√≠a',
    
    # Palabras comunes
    'el', 'la', 'los', 'las', 'un', 'una', 'y', 'de', 'en', 'con',
    'por', 'para', 'sin', 'sobre', 'entre', 'hacia', 'desde', 'que',
    'como', 'cuando', 'donde', 'porque', 'si', 'no', 's√≠', 'tambi√©n',
    'muy', 'm√°s', 'menos', 'todo', 'nada', 'algo', 'siempre', 'nunca',
    'ahora', 'despu√©s', 'antes', 'aqu√≠', 'all√≠', 'lejos', 'cerca',
    
    # Verbos
    'es', 'era', 'soy', 'eres', 'somos', 'son', 'est√°', 'estaba',
    'tengo', 'tiene', 'quiero', 'puedo', 'debo', 's√©', 'sabe',
    'ama', 'odia', 'vive', 'muere', 'nace', 'crece', 'cambia',
    'escribe', 'lee', 'canta', 'baila', 'corre', 'salta', 'vuela',
    'piensa', 'siente', 'recuerda', 'olvida', 'encuentra', 'pierde',
    
    # Ingl√©s b√°sico
    'hello', 'world', 'love', 'life', 'death', 'soul', 'heart',
    'poetry', 'verse', 'night', 'day', 'time', 'light', 'shadow',
    'sea', 'sky', 'earth', 'fire', 'water', 'air', 'blood', 'tear'
]

# Crear mapeos
for i, word in enumerate(poem_words[:100]):  # M√°ximo 100 palabras
    vocab[word] = i
    id_to_token[i] = word

print(f"üìö Vocabulario creado: {len(vocab)} palabras")
print("Primeras 10:", list(vocab.keys())[:10])

# 2. EMBEDDINGS CON SENTIDO
vocab_size = len(vocab)
d_model = 48

print(f"\nüé® Creando embeddings inteligentes...")

# Crear espacio sem√°ntico
embedding = np.zeros((vocab_size, d_model), dtype=np.float32)

# Semillas para dimensiones sem√°nticas
np.random.seed(42)
semantic_axes = np.random.randn(10, d_model)  # 10 ejes sem√°nticos

for word, idx in vocab.items():
    # Vector base aleatorio
    vec = np.random.randn(d_model) * 0.1
    
    # A√±adir significado seg√∫n la palabra
    if word in ['amor', 'love', 'cari√±o', 'affection']:
        vec += semantic_axes[0] * 0.5  # Eje amor
    elif word in ['vida', 'life', 'existencia']:
        vec += semantic_axes[1] * 0.5  # Eje vida
    elif word in ['muerte', 'death', 'fin']:
        vec += semantic_axes[2] * 0.5  # Eje muerte
    elif word in ['poes√≠a', 'poetry', 'verso', 'verse']:
        vec += semantic_axes[3] * 0.5  # Eje poes√≠a
    elif word in ['noche', 'night', 'oscuridad']:
        vec += semantic_axes[4] * 0.3  # Eje noche
    elif word in ['luz', 'light', 'brillo']:
        vec += semantic_axes[5] * 0.3  # Eje luz
    elif word in ['tristeza', 'sadness', 'dolor', 'pain']:
        vec += semantic_axes[6] * 0.4  # Eje tristeza
    elif word in ['alegr√≠a', 'joy', 'felicidad']:
        vec += semantic_axes[7] * 0.4  # Eje alegr√≠a
    
    # Palabras relacionadas tienen embeddings similares
    if word in ['cabellos', 'pelo', 'melena']:
        vec = embedding[vocab.get('cuerpo', 0)] * 0.8 + np.random.randn(d_model) * 0.1
    
    embedding[idx] = vec

print(f"   Embedding shape: {embedding.shape}")

# 3. LM HEAD INTELIGENTE
print(f"\nüß† Creando LM head...")
lm_head = np.random.randn(d_model, vocab_size).astype(np.float32) * 0.1

# Hacer que palabras relacionadas tengan probabilidades similares
for i in range(vocab_size):
    word1 = id_to_token[i]
    
    # Buscar palabras relacionadas
    for j in range(vocab_size):
        if i == j:
            continue
            
        word2 = id_to_token[j]
        
        # Si son sin√≥nimos o relacionados
        related = False
        related_pairs = [
            ('amor', 'love'), ('vida', 'life'), ('muerte', 'death'),
            ('poes√≠a', 'poetry'), ('noche', 'night'), ('luz', 'light'),
            ('cabellos', 'pelo'), ('cuerpo', 'body')
        ]
        
        for pair in related_pairs:
            if (word1 == pair[0] and word2 == pair[1]) or (word1 == pair[1] and word2 == pair[0]):
                related = True
                break
        
        if related:
            # Hacer sus logits similares
            lm_head[:, i] = lm_head[:, i] * 0.7 + lm_head[:, j] * 0.3

# 4. CONFIGURACI√ìN
config = {
    'vocab_size': vocab_size,
    'd_model': d_model,
    'n_layers': 3,
    'is_poet': True,
    'author': 'arachne',
    'created': 'from_scratch'
}

# 5. GUARDAR
model_data = {
    'config': config,
    'embedding': embedding,
    'lm_head': lm_head,
    'vocab': vocab,
    'id_to_token': id_to_token,
    'blocks': [],  # Para compatibilidad
    'metadata': {
        'type': 'functional_poet',
        'words': list(vocab.keys()),
        'note': 'Poeta creado desde cero con vocabulario sensato'
    }
}

output_file = 'poeta_funcional.pkl'
with open(output_file, 'wb') as f:
    pickle.dump(model_data, f)

print(f"\n‚úÖ POETA FUNCIONAL CREADO: {output_file}")
print(f"   ‚Ä¢ Palabras: {len(vocab)}")
print(f"   ‚Ä¢ Dimensiones: {d_model}D")
print(f"   ‚Ä¢ Embedding shape: {embedding.shape}")

# 6. PRUEBA R√ÅPIDA
print(f"\nüß™ Prueba r√°pida:")
test_words = ['amor', 'vida', 'poes√≠a', 'cabellos', 'hello']
for word in test_words:
    if word in vocab:
        idx = vocab[word]
        vec = embedding[idx]
        print(f"   '{word}' (ID {idx}): norma={np.linalg.norm(vec):.3f}")
    else:
        print(f"   '{word}': ‚ùå No en vocabulario")
